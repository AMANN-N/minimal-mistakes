---
layout: portfolio-single
title: "Deep Neural Network from Scratch"
excerpt: "Implementation of a multi-layer deep neural network from scratch with backpropagation and various optimizers."
icon: "fas fa-network-wired"
image: "/assets/img/implementations/dnn-cover.png"
github: "https://github.com/AMANN-N/ml-playground/tree/main/Naive%20Deep%20Neural%20Network"
category: "deep-learning"
---

**Type:** Deep Learning Fundamentals  
**Framework:** NumPy  

## Overview
Complete implementation of a deep neural network from scratch, including forward propagation, backpropagation, and various optimization techniques.

## Key Components
- Multi-layer architecture
- Activation functions (ReLU, Sigmoid, Tanh)
- Backpropagation algorithm
- Optimizers (SGD, Momentum, Adam)
- Weight initialization strategies

## Technologies Used
- **Framework:** NumPy, Matplotlib
- **Concepts:** Backpropagation, Gradient descent, Deep learning fundamentals
- **Applications:** Classification, Regression, Feature learning

## GitHub Repository
ðŸ”— [View on GitHub](https://github.com/AMANN-N/ml-playground/tree/main/Naive%20Deep%20Neural%20Network)
