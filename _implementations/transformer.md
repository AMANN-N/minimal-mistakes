---
title: "Transformer Implementation"
excerpt: "A from-scratch implementation of the Transformer architecture in PyTorch."
icon: "fas fa-code"
---

## Overview
This is a clean, educational implementation of the Transformer model as described in "Attention Is All You Need".

## Features
*   Multi-head attention
*   Positional encoding
*   Encoder-Decoder architecture
