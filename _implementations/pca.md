---
layout: portfolio-single
title: "PCA - Principal Component Analysis"
excerpt: "Implementation of Principal Component Analysis from scratch for dimensionality reduction and feature extraction."
icon: "fas fa-compress"
image: "/assets/img/implementations/pca-cover.png"
github: "https://github.com/AMANN-N/ml-playground/tree/main/PCA"
category: "ml-algorithms"
---

<div class="notice--info" style="display: flex; flex-wrap: wrap; gap: 20px; align-items: center; background: #e8f4f8; border-left: 4px solid #17a2b8; padding: 1em;">
  <div>
    <span style="color: #6c757d; font-size: 0.9em; text-transform: uppercase; letter-spacing: 1px;">Type</span><br>
    <strong>Dimensionality Reduction Algorithm</strong>
  </div>
  <div>
    <span style="color: #6c757d; font-size: 0.9em; text-transform: uppercase; letter-spacing: 1px;">Framework</span><br>
    <strong>NumPy</strong>
  </div>
</div>  

## Overview
Implementation of Principal Component Analysis (PCA) from scratch for reducing dimensionality while preserving maximum variance in the data.

## Key Components
- Covariance matrix computation
- Eigenvalue decomposition
- Principal component selection
- Data transformation
- Variance explained analysis

## Technologies Used
- **Framework:** NumPy, Matplotlib
- **Concepts:** Linear algebra, Dimensionality reduction, Feature extraction
- **Applications:** Data visualization, Noise reduction, Feature engineering

## GitHub Repository
ðŸ”— [View on GitHub](https://github.com/AMANN-N/ml-playground/tree/main/PCA)
